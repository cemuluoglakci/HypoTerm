{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* Relational Database (MySQL)\n",
    "* Wikipedia on NoSql DB (Mongo DB)\n",
    "\n",
    "Outputs:\n",
    "* Topics table\n",
    "* Hypothetical terms table\n",
    "* Valid terms table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, 'data')\n",
    "\n",
    "sys.path.append(os.path.join(parent_dir))\n",
    "\n",
    "from src.sqldb import HallucinationDb\n",
    "from wiki.search import WikiSearcher\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = HallucinationDb(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = json.load(open(os.path.join(data_dir, 'intermediate', 'topics.json')))\n",
    "topic_table = db.GetTableDefinition(db.TOPIC_TABLE)\n",
    "\n",
    "for index, topic in enumerate(topics):\n",
    "    string_list = topic.split(\":\")\n",
    "    name = string_list[0]\n",
    "    explanation = string_list[1]\n",
    "    insert_statement = topic_table.insert().values(name=name, explanation=explanation)\n",
    "    db.sql.execute(insert_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Hypothetical Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_terms_path = os.path.join(data_dir, \"intermediate\", \"related_terms.csv\")\n",
    "hypothetical_terms_df = pd.read_csv(hypothetical_terms_path, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = \"\"\n",
    "topic_id = 0\n",
    "\n",
    "nonexistent_table = db.GetTableDefinition(db.NONEXISTENT_TABLE)\n",
    "\n",
    "for index, row in hypothetical_terms_df.iterrows():\n",
    "    if topic_name != row[\"topic\"]:\n",
    "        topic_name = row[\"topic\"]\n",
    "        topic_id += 1\n",
    "\n",
    "    insert_statement = nonexistent_table.insert().values(\n",
    "        term=row[\"term\"],\n",
    "        explanation=row[\"explanation\"],\n",
    "        topic_id=topic_id, \n",
    "        )\n",
    "    db.sql.execute(insert_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving LLM Suggested Valid Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_searcher = WikiSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_terms_table = db.GetTableDefinition(db.REAL_TERMS_TABLE)\n",
    "nonexistent_real_table = db.GetTableDefinition(db.NONEXISTENT_REAL_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(list_str):\n",
    "    list_str = list_str.replace(\"... \", \"' \")\n",
    "    if  \",\" in list_str:\n",
    "        terms_list=[term.strip()[1:-1] for term in list_str[1:-1].split(\",\")]\n",
    "    else:\n",
    "        terms_list = [re.sub(r'[0-9.]', \"\", term).strip() for term in list_str.split(\"\\n\")]\n",
    "    return terms_list\n",
    "\n",
    "def check_term(term_name):\n",
    "    result_row = db.sql.execute(real_terms_table.select().where(real_terms_table.c.term == term_name)).fetchone()\n",
    "    if result_row:\n",
    "        return result_row[real_terms_table.c.id]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = []\n",
    "definition_list = []\n",
    "topic_list = []\n",
    "parent_term_list = []\n",
    "\n",
    "for index, row in hypothetical_terms_df.iterrows():\n",
    "    related_terms = str2list(row[\"related_term\"])\n",
    "\n",
    "    for term in related_terms:\n",
    "        definition = wiki_searcher.get_definition(term)\n",
    "        if definition not in [\"None\", \"ambiguous\"]:\n",
    "            term_id = check_term(term)\n",
    "            if term_id == 0:\n",
    "                term_insert_result = db.sql.execute(\n",
    "                    real_terms_table.insert().values(\n",
    "                        term=term,\n",
    "                        explanation=definition,\n",
    "                        source_id=1\n",
    "                ))\n",
    "                term_id = term_insert_result.inserted_primary_key[0]\n",
    "            db.sql.execute(nonexistent_real_table.insert().values(\n",
    "                nonexistent_id = index+1,\n",
    "                real_id = term_id\n",
    "            ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
