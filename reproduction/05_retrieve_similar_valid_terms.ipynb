{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* Vector Database (Milvus)\n",
    "* Relational Database (MySQL)\n",
    "\n",
    "Outputs:\n",
    "* Valid terms from title similarity\n",
    "* Valid terms from definition similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "ver\n"
     ]
    }
   ],
   "source": [
    "# import local modules\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, 'data')\n",
    "\n",
    "sys.path.append(os.path.join(parent_dir))\n",
    "\n",
    "import settings\n",
    "from wiki.embeddings import Embeddings\n",
    "from wiki.search import WikiSearcher\n",
    "from src.sqldb import HallucinationDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin d:\\coding\\HypoTerm\\venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "CUDA SETUP: Loading binary d:\\coding\\HypoTerm\\venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n",
      "argument of type 'WindowsPath' is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\HypoTerm\\venv\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "d:\\coding\\HypoTerm\\venv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "wiki_embeddings = Embeddings(settings)\n",
    "db = HallucinationDb(settings)\n",
    "wiki_searcher = WikiSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_terms_path = os.path.join(data_dir, \"intermediate\", \"related_terms.csv\")\n",
    "hypothetical_terms_df = pd.read_csv(hypothetical_terms_path, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_terms_table = db.GetTableDefinition(db.REAL_TERMS_TABLE)\n",
    "nonexistent_real_table = db.GetTableDefinition(db.NONEXISTENT_REAL_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_term(term_name):\n",
    "    result_row = db.sql.execute(real_terms_table.select().where(real_terms_table.c.term == term_name)).fetchone()\n",
    "    if result_row:\n",
    "        return result_row[real_terms_table.c.id]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"wiki_title\"\n",
    "start_from = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in hypothetical_terms_df.iloc[start_from:].iterrows():\n",
    "    print(\"Index: \", index)\n",
    "    fake_term = row[\"term\"]\n",
    "    similarity_search = wiki_embeddings.vector_search(collection_name, fake_term)\n",
    "    for hits in similarity_search:\n",
    "        for hit in hits:\n",
    "            real_term_title = hit.entity.get('title')\n",
    "            real_term_definition = wiki_searcher.get_definition(real_term_title)\n",
    "\n",
    "            if real_term_definition in [\"None\", \"ambiguous\"]:\n",
    "                continue\n",
    "\n",
    "            term_id = check_term(real_term_title)\n",
    "            \n",
    "            if term_id == 0:\n",
    "                term_insert_result = db.sql.execute(\n",
    "                    real_terms_table.insert().values(\n",
    "                        term=real_term_title,\n",
    "                        explanation=real_term_definition,\n",
    "                        source_id=2\n",
    "                ))\n",
    "                term_id = term_insert_result.inserted_primary_key[0]\n",
    "\n",
    "            db.sql.execute(nonexistent_real_table.insert().values(\n",
    "                nonexistent_id = index+1,\n",
    "                real_id = term_id\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"wiki_text\"\n",
    "start_from = 0\n",
    "partition_batch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_description_table = db.GetTableDefinition(db.SIMILAR_DESCRIPTION_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_list = [partition.name for partition in wiki_embeddings.get_collection(collection_name).partitions if partition.name != \"_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_index, f_row in hypothetical_terms_df.iloc[start_from:].iterrows():\n",
    "    fake_term = f_row[\"term\"]\n",
    "    fake_definition = f_row[\"explanation\"]\n",
    "\n",
    "    similarity_data = []\n",
    "    for i in tqdm(range(0, len(partition_list), partition_batch), desc=f\"Index {f_index}:{fake_term}\"):\n",
    "        partition_names = partition_list[i:i+partition_batch]\n",
    "\n",
    "        similarity_search = wiki_embeddings.vector_search(collection_name, fake_definition, partition_names=partition_names)\n",
    "        for hits in similarity_search:\n",
    "            for hit in hits:\n",
    "                similarity_data.append([hit.id, hit.distance, hit.entity.get('title'), hit.entity.get('text')[:9000]])\n",
    "\n",
    "    similarity_df = pd.DataFrame(similarity_data, columns=[\"_id\", \"distance\", \"title\", \"text\"]).sort_values(by=\"distance\").head(10)\n",
    "\n",
    "    for r_index, r_row in similarity_df.iterrows():\n",
    "        real_term_title = r_row[\"title\"]\n",
    "        real_term_text = r_row[\"text\"]\n",
    "        wiki_id = r_row[\"_id\"]\n",
    "        real_term_definition = wiki_searcher.get_definition_by_id(wiki_id)\n",
    "\n",
    "        if real_term_definition in [\"None\", \"ambiguous\"]:\n",
    "            real_term_definition = real_term_text\n",
    "\n",
    "        term_id = check_term(real_term_title)\n",
    "        if term_id == 0:\n",
    "            term_insert_result = db.sql.execute(\n",
    "                real_terms_table.insert().values(\n",
    "                    term=real_term_title,\n",
    "                    explanation=real_term_definition,\n",
    "                    source_id=3\n",
    "            ))\n",
    "            term_id = term_insert_result.inserted_primary_key[0]\n",
    "\n",
    "        db.sql.execute(nonexistent_real_table.insert().values(\n",
    "            nonexistent_id = f_index+1,\n",
    "            real_id = term_id\n",
    "        ))\n",
    "\n",
    "        db.sql.execute(similar_description_table.insert().values(\n",
    "            wiki_id = wiki_id,\n",
    "            title = real_term_title,\n",
    "            text = real_term_text\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
