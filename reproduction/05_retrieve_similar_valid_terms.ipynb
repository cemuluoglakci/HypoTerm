{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* Vector Database (Milvus)\n",
    "* Relational Database (MySQL)\n",
    "\n",
    "Outputs:\n",
    "* Valid terms from title similarity\n",
    "* Valid terms from definition similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local modules\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, 'data')\n",
    "\n",
    "sys.path.append(os.path.join(parent_dir))\n",
    "\n",
    "import settings\n",
    "from wiki.embeddings import Embeddings\n",
    "from wiki.search import WikiSearcher\n",
    "from src.sqldb import HallucinationDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = Embeddings(settings)\n",
    "db = HallucinationDb(settings)\n",
    "wiki_searcher = WikiSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_terms_path = os.path.join(data_dir, \"intermediate\", \"related_terms.csv\")\n",
    "hypothetical_terms_df = pd.read_csv(hypothetical_terms_path, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_terms_table = db.GetTableDefinition(db.REAL_TERMS_TABLE)\n",
    "nonexistent_real_table = db.GetTableDefinition(db.NONEXISTENT_REAL_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_term(term_name):\n",
    "    result_row = db.sql.execute(real_terms_table.select().where(real_terms_table.c.term == term_name)).fetchone()\n",
    "    if result_row:\n",
    "        return result_row[real_terms_table.c.id]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"wiki_title\"\n",
    "start_from = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in hypothetical_terms_df.iloc[start_from:].iterrows():\n",
    "    print(\"Index: \", index)\n",
    "    fake_term = row[\"term\"]\n",
    "    similarity_search = wiki_embeddings.vector_search(collection_name, fake_term)\n",
    "    for hits in similarity_search:\n",
    "        for hit in hits:\n",
    "            real_term_title = hit.entity.get('title')\n",
    "            real_term_definition = wiki_searcher.get_definition(real_term_title)\n",
    "\n",
    "            if real_term_definition in [\"None\", \"ambiguous\"]:\n",
    "                continue\n",
    "\n",
    "            term_id = check_term(real_term_title)\n",
    "            \n",
    "            if term_id == 0:\n",
    "                term_insert_result = db.sql.execute(\n",
    "                    real_terms_table.insert().values(\n",
    "                        term=real_term_title,\n",
    "                        explanation=real_term_definition,\n",
    "                        source_id=2\n",
    "                ))\n",
    "                term_id = term_insert_result.inserted_primary_key[0]\n",
    "\n",
    "            db.sql.execute(nonexistent_real_table.insert().values(\n",
    "                nonexistent_id = index+1,\n",
    "                real_id = term_id\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"wiki_text\"\n",
    "start_from = 0\n",
    "partition_batch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_description_table = db.GetTableDefinition(db.SIMILAR_DESCRIPTION_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_list = [partition.name for partition in wiki_embeddings.get_collection(collection_name).partitions if partition.name != \"_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_index, f_row in hypothetical_terms_df.iloc[start_from:].iterrows():\n",
    "    fake_term = f_row[\"term\"]\n",
    "    fake_definition = f_row[\"explanation\"]\n",
    "\n",
    "    similarity_data = []\n",
    "    for i in tqdm(range(0, len(partition_list), partition_batch), desc=f\"Index {f_index}:{fake_term}\"):\n",
    "        partition_names = partition_list[i:i+partition_batch]\n",
    "\n",
    "        similarity_search = wiki_embeddings.vector_search(collection_name, fake_definition, partition_names=partition_names)\n",
    "        for hits in similarity_search:\n",
    "            for hit in hits:\n",
    "                similarity_data.append([hit.id, hit.distance, hit.entity.get('title'), hit.entity.get('text')[:9000]])\n",
    "\n",
    "    similarity_df = pd.DataFrame(similarity_data, columns=[\"_id\", \"distance\", \"title\", \"text\"]).sort_values(by=\"distance\").head(10)\n",
    "\n",
    "    for r_index, r_row in similarity_df.iterrows():\n",
    "        real_term_title = r_row[\"title\"]\n",
    "        real_term_text = r_row[\"text\"]\n",
    "        wiki_id = r_row[\"_id\"]\n",
    "        real_term_definition = wiki_searcher.get_definition_by_id(wiki_id)\n",
    "\n",
    "        if real_term_definition in [\"None\", \"ambiguous\"]:\n",
    "            real_term_definition = real_term_text\n",
    "\n",
    "        term_id = check_term(real_term_title)\n",
    "        if term_id == 0:\n",
    "            term_insert_result = db.sql.execute(\n",
    "                real_terms_table.insert().values(\n",
    "                    term=real_term_title,\n",
    "                    explanation=real_term_definition,\n",
    "                    source_id=3\n",
    "            ))\n",
    "            term_id = term_insert_result.inserted_primary_key[0]\n",
    "\n",
    "        db.sql.execute(nonexistent_real_table.insert().values(\n",
    "            nonexistent_id = f_index+1,\n",
    "            real_id = term_id\n",
    "        ))\n",
    "\n",
    "        db.sql.execute(similar_description_table.insert().values(\n",
    "            wiki_id = wiki_id,\n",
    "            title = real_term_title,\n",
    "            text = real_term_text\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
