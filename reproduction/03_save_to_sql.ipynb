{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* Relational Database (MySQL)\n",
    "* Wikipedia on NoSql DB (Mongo DB)\n",
    "\n",
    "Outputs:\n",
    "* Topics table\n",
    "* Hypothetical terms table\n",
    "* Valid terms table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "ver\n"
     ]
    }
   ],
   "source": [
    "# import local modules\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, 'data')\n",
    "\n",
    "sys.path.append(os.path.join(parent_dir))\n",
    "\n",
    "from src.sqldb import HallucinationDb\n",
    "from wiki.search import WikiSearcher\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = HallucinationDb(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = json.load(open(os.path.join(data_dir, 'intermediate', 'topics.json')))\n",
    "topic_table = db.GetTableDefinition(db.TOPIC_TABLE)\n",
    "\n",
    "for index, topic in enumerate(topics):\n",
    "    string_list = topic.split(\":\")\n",
    "    name = string_list[0]\n",
    "    explanation = string_list[1]\n",
    "    insert_statement = topic_table.insert().values(name=name, explanation=explanation)\n",
    "    db.sql.execute(insert_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Hypothetical Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_terms_path = os.path.join(data_dir, \"intermediate\", \"related_terms.csv\")\n",
    "hypothetical_terms_df = pd.read_csv(hypothetical_terms_path, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = \"\"\n",
    "topic_id = 0\n",
    "\n",
    "nonexistent_table = db.GetTableDefinition(db.NONEXISTENT_TABLE)\n",
    "\n",
    "for index, row in hypothetical_terms_df.iterrows():\n",
    "    if topic_name != row[\"topic\"]:\n",
    "        topic_name = row[\"topic\"]\n",
    "        topic_id += 1\n",
    "\n",
    "    insert_statement = nonexistent_table.insert().values(\n",
    "        term=row[\"term\"],\n",
    "        explanation=row[\"explanation\"],\n",
    "        topic_id=topic_id, \n",
    "        )\n",
    "    db.sql.execute(insert_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving LLM Suggested Valid Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_searcher = WikiSearcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_terms_table = db.GetTableDefinition(db.REAL_TERMS_TABLE)\n",
    "nonexistent_real_table = db.GetTableDefinition(db.NONEXISTENT_REAL_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(list_str):\n",
    "    list_str = list_str.replace(\"... \", \"' \")\n",
    "    if  \",\" in list_str:\n",
    "        terms_list=[term.strip()[1:-1] for term in list_str[1:-1].split(\",\")]\n",
    "    else:\n",
    "        terms_list = [re.sub(r'[0-9.]', \"\", term).strip() for term in list_str.split(\"\\n\")]\n",
    "    return terms_list\n",
    "\n",
    "def check_term(term_name):\n",
    "    result_row = db.sql.execute(real_terms_table.select().where(real_terms_table.c.term == term_name)).fetchone()\n",
    "    if result_row:\n",
    "        return result_row[real_terms_table.c.id]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Nanotechnology'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\coding\\HypoTerm\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\coding\\HypoTerm\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\coding\\HypoTerm\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Nanotechnology'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m related_terms \u001b[38;5;241m=\u001b[39m str2list(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelated_term\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m related_terms:\n\u001b[1;32m---> 10\u001b[0m     definition \u001b[38;5;241m=\u001b[39m \u001b[43mhypothetical_terms_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m definition \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mambiguous\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     12\u001b[0m         term_id \u001b[38;5;241m=\u001b[39m check_term(term)\n",
      "File \u001b[1;32md:\\coding\\HypoTerm\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\coding\\HypoTerm\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Nanotechnology'"
     ]
    }
   ],
   "source": [
    "term_list = []\n",
    "definition_list = []\n",
    "topic_list = []\n",
    "parent_term_list = []\n",
    "\n",
    "for index, row in hypothetical_terms_df.iterrows():\n",
    "    related_terms = str2list(row[\"related_term\"])\n",
    "\n",
    "    for term in related_terms:\n",
    "        definition = wiki_searcher.get_definition(term)\n",
    "        if definition not in [\"None\", \"ambiguous\"]:\n",
    "            term_id = check_term(term)\n",
    "            if term_id == 0:\n",
    "                term_insert_result = hypothetical_terms_df.sql.execute(\n",
    "                    real_terms_table.insert().values(\n",
    "                        term=term,\n",
    "                        explanation=definition,\n",
    "                        source_id=1\n",
    "                ))\n",
    "                term_id = term_insert_result.inserted_primary_key[0]\n",
    "            hypothetical_terms_df.sql.execute(nonexistent_real_table.insert().values(\n",
    "                nonexistent_id = index+1,\n",
    "                real_id = term_id\n",
    "            ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
